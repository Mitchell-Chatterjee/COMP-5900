{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQgwzTa26v3F"
   },
   "source": [
    "# **PyTorch tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mbalT7vDnbIc"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pickle as pkl\n",
    "import torch \n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c7-Ec0eq290"
   },
   "source": [
    "# Tensors\n",
    "\n",
    "* Its like a numpy ndarray \n",
    "* Doesn't know anything about deep learning or computational graphs or gradients\n",
    "* **Also runs runs on GPU !**\n",
    "* Can convert back and forth from the numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YJHGlwfDnpS-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFBBsfdQqdtK"
   },
   "source": [
    "What just happened? There's a nan.... \n",
    "\n",
    "We just declared an uninitialized tensor. The data inside is garbage, it is just random stuff that was in the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SXdYHKdjpoUq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View the shape of a tensor\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8vjtIpFTqHJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6358, 0.5989, 0.7771],\n",
      "        [0.0673, 0.3642, 0.4303]])\n"
     ]
    }
   ],
   "source": [
    "#Declaring a random tensor of shape (2,3)\n",
    "x = torch.rand(2, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "W1If6NemM5FO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000, 0.3000],\n",
       "        [0.4000, 0.5000, 0.6000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Declaring a custom tensor\n",
    "#What's inside can be any python list or numpy array\n",
    "\n",
    "x = torch.Tensor(\n",
    "    [\n",
    "        [0.1, 0.2, 0.3],\n",
    "        [0.4, 0.5, 0.6]\n",
    "    ]\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AGpPZj5cNM58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Declaring an empty tensor and a tensor filled with 1s\n",
    "zeros = torch.zeros(2,3)\n",
    "print(zeros)\n",
    "\n",
    "print()\n",
    "\n",
    "ones = torch.ones(2,3)\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d-IjC5S7N8TM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.3000],\n",
      "        [0.4000, 0.5000, 0.6000]])\n",
      "tensor([[ 0.1000,  0.2000,  0.3000],\n",
      "        [ 0.4000, 24.0000,  0.6000]])\n"
     ]
    }
   ],
   "source": [
    "#Changing elements of tensor\n",
    "print(x)\n",
    "\n",
    "x[1][1] = 24\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0_6N1gFaO6AZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1000,  0.2000,  0.3000],\n",
      "        [ 0.4000, 24.0000,  0.6000]])\n",
      "tensor([ 0.2000, 24.0000])\n"
     ]
    }
   ],
   "source": [
    "#Numpy indexing\n",
    "#if we only want the second column\n",
    "print(x)\n",
    "\n",
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "mgMUwfRnQbfn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1000,  0.2000,  0.3000],\n",
      "        [ 0.4000, 24.0000,  0.6000]])\n",
      "\n",
      "tensor([[ 0.1000,  0.2000],\n",
      "        [ 0.3000,  0.4000],\n",
      "        [24.0000,  0.6000]])\n",
      "\n",
      "tensor([[ 0.1000,  0.2000],\n",
      "        [ 0.3000,  0.4000],\n",
      "        [24.0000,  0.6000]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "print(x)\n",
    "print()\n",
    "print(x.view(3,2))\n",
    "print()\n",
    "\n",
    "print(x.view(3,-1))\n",
    "print()\n",
    "#Give me 3 rows, you figure out the appropriate number of colomns. \n",
    "#Only one of the axis value can be -1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKj-s0EtrKAr"
   },
   "source": [
    "### Tensors support most numpy operations like broadcasting, arithmetic, reshaping, indexing, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "H1ELeyq-PeWY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "y :\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6]\n",
    "    ]\n",
    ")\n",
    "\n",
    "y = torch.Tensor([[2]*3]*2)\n",
    "\n",
    "print(f\"x :\\n{x}\\n\")\n",
    "print(f\"y :\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "S4QdcusOqL4o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mWXmQW7IOgPq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mLfrY93QOl1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6yuFwACUOl8v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x :\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "z :\n",
      "tensor([[3.],\n",
      "        [4.]])\n",
      "\n",
      "x * z :\n",
      "tensor([[ 3.,  6.,  9.],\n",
      "        [16., 20., 24.]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Broadcasting\n",
    "print(f\"x :\\n{x}\\n\")\n",
    "\n",
    "\n",
    "z = torch.tensor([3.0 ,4.0]).view(-1,1)\n",
    "print(f\"z :\\n{z}\\n\")\n",
    "\n",
    "print(f\"x * z :\\n{x * z}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X8DO-gKBrJWX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# move tensor to GPU using\n",
    "x = x.cuda()\n",
    "print(x)\n",
    "\n",
    "\n",
    "# move back to CPU\n",
    "x = x.cpu()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Efm6yU8uRxyk"
   },
   "source": [
    "###Other Basic operations can be found here: https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52x8xJYxQyDa"
   },
   "source": [
    "###Autograd\n",
    "\n",
    "Tensors can be initialized with an extra argument which lets them use autograd.\n",
    "\n",
    "Autograd tracks the gradients for each computation of a tensor.\n",
    "\n",
    "Some older PyTorch tutorials will use Variable to wrap a tensor to use autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BULflfvqrLz9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "yDN-ru_GKbxT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x^3 = 9\n",
    "output = x.pow(3)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "GDJKfnhzLkJw"
   },
   "outputs": [],
   "source": [
    "#Calling backward computes the derivative of whatever was calculated\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iCYYAM_ILmO7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can call tensor.grad to see the computed gradient.\n",
    "#Example here, d/dx (x^3) = 3x^2, which is 3 * 2^2 = 12\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5GLROXKhLnLn"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-aa6776c6988e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Only Floating point tensors can use autograd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m x = torch.tensor(\n\u001b[0m\u001b[0;32m      3\u001b[0m     [\n\u001b[0;32m      4\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "#Only Floating point tensors can use autograd\n",
    "x = torch.tensor(\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [4,5,6]\n",
    "    ]\n",
    ",requires_grad = True\n",
    ")\n",
    "\n",
    "x + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLtvOAKuTtMC"
   },
   "source": [
    "### More elaborate example of gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dh-QQNIJSO-U"
   },
   "outputs": [],
   "source": [
    "#We declare two tensors, a and b\n",
    "a = torch.tensor(\n",
    "    [\n",
    "        [1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 1.0]\n",
    "    ]\n",
    ",requires_grad = True\n",
    ")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYOy04ftq2E_"
   },
   "outputs": [],
   "source": [
    "b = torch.tensor(\n",
    "    [\n",
    "        [2.0, 2.0],\n",
    "        [2.0, 2.0],\n",
    "        [2.0, 2.0]\n",
    "    ]\n",
    ",requires_grad = True\n",
    ")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cszJcyCfviLB"
   },
   "outputs": [],
   "source": [
    "# We perform a matrix multiplication of a and b\n",
    "c = a.matmul(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSNR58WTTWcV"
   },
   "outputs": [],
   "source": [
    "#We then multiply again, and perform a broadcast addition\n",
    "d = (c.pow(2) + 5)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5iFOtfLcSmnz"
   },
   "outputs": [],
   "source": [
    "# Take a mean\n",
    "e = d.mean()\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-P_vz6xUSrLc"
   },
   "outputs": [],
   "source": [
    "#Compute gradients\n",
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5hj6PBqT2d2"
   },
   "outputs": [],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)\n",
    "#print(d.grad)\n",
    "#print(c.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0ikUexfU_oG"
   },
   "source": [
    "### Gradients are accumulated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-CJQgzs-VaGG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : tensor([[1.]], requires_grad=True)\n",
      "b : tensor([[1.]], grad_fn=<PowBackward0>)\n",
      "c : tensor([[1.]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.eye(1, requires_grad=True)\n",
    "\n",
    "b = a**2\n",
    "c = a**3\n",
    "\n",
    "print(f\"a : {a}\")\n",
    "print(f\"b : {b}\")\n",
    "print(f\"c : {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gPPPwoINVxOl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradient after b, we get d/dx x^2 = 2x = 2\n",
    "b.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1eyERhqDVxcV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute gradient after c, we get d/dx x^3 = 3x^2 = 3\n",
    "# a's gradient term will not be 3, because gradient accumulates. 2 + 3 = 5\n",
    "c.backward()\n",
    "a.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBptCmbPVd1T"
   },
   "source": [
    "# Dynamic Computation Graphs\n",
    "\n",
    "* PyTorch maintains a graph that records all of the operations performed on variables as you execute your operations.\n",
    "* This results in a directed acyclic graph whose leaves are the input variables and roots are the output variables. \n",
    "* By tracing this graph from roots to leaves, you can automatically compute the gradients using the chain rule.\n",
    "\n",
    "![alt text](https://media.giphy.com/media/28g130aXBImNlG3dhG/giphy.gif)\n",
    "\n",
    "\n",
    "## Modules\n",
    "\n",
    "* Differentiable objects; may store state or learnable weights\n",
    "* Can define a new module; it inputs and outputs Tensors and corresponding input and output functions\n",
    "\n",
    "\n",
    "### torch.nn\n",
    "\n",
    "Neural networks can be constructed using the **torch.nn** package. \n",
    "\n",
    "* Linear layers - nn.Linear, nn.Bilinear\n",
    "* Convolution Layers - nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.ConvTranspose2d\n",
    "* Nonlinearities - nn.Sigmoid, nn.Tanh, nn.ReLU, nn.LeakyReLU\n",
    "* Pooling Layers - nn.MaxPool1d, nn.AveragePool2d\n",
    "* Recurrent Networks - nn.LSTM, nn.GRU\n",
    "* Normalization - nn.BatchNorm2d\n",
    "* Dropout - nn.Dropout, nn.Dropout2d\n",
    "* Embedding - nn.Embedding\n",
    "* Loss Functions - nn.MSELoss, nn.CrossEntropyLoss, nn.NLLLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "X7sDF7eZVgCY"
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \n",
    "        Args:\n",
    "            - D_in : input dimension of the data\n",
    "            - H : size of the first hidden layer\n",
    "            - D_out : size of the output/ second layer\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__() # intialize recursively \n",
    "        self.linear1 = torch.nn.Linear(D_in, H) # create a linear layer \n",
    "        self.linear2 = torch.nn.Linear(H, D_out) \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and\n",
    "        return a tensor of output data. We can use \n",
    "        Modules defined in the constructor as well as arbitrary \n",
    "        operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "646n1JNbV2N2"
   },
   "outputs": [],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EiPaaHrmV4WM"
   },
   "outputs": [],
   "source": [
    "# Create random Tensors to hold inputs and outputs\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out, requires_grad=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "y3I9PS0bWB4H"
   },
   "outputs": [],
   "source": [
    "# Construct our model by instantiating the class defined above\n",
    "\n",
    "model = TwoLayerNet(D_in, H, D_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_MvupktWI9v"
   },
   "source": [
    "### Construct our loss function and an Optimizer. \n",
    "\n",
    "The call to **model.parameters()** in the SGD constructor will contain the learnable parameters of the two nn.Linear modules which are part of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "EEMxmtdfWF4b"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# optimizer \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DwMgX35RWLs3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0    Loss : 705.1826782226562\n",
      "Epoch : 1    Loss : 602.975341796875\n",
      "Epoch : 2    Loss : 518.596435546875\n",
      "Epoch : 3    Loss : 447.64068603515625\n",
      "Epoch : 4    Loss : 387.1727294921875\n",
      "Epoch : 5    Loss : 335.1552429199219\n",
      "Epoch : 6    Loss : 290.1211853027344\n",
      "Epoch : 7    Loss : 250.97625732421875\n",
      "Epoch : 8    Loss : 216.8766632080078\n",
      "Epoch : 9    Loss : 187.1503143310547\n",
      "Epoch : 10    Loss : 161.245849609375\n",
      "Epoch : 11    Loss : 138.69873046875\n",
      "Epoch : 12    Loss : 119.1087646484375\n",
      "Epoch : 13    Loss : 102.12528991699219\n",
      "Epoch : 14    Loss : 87.4371109008789\n",
      "Epoch : 15    Loss : 74.7660903930664\n",
      "Epoch : 16    Loss : 63.862674713134766\n",
      "Epoch : 17    Loss : 54.50291061401367\n",
      "Epoch : 18    Loss : 46.48621368408203\n",
      "Epoch : 19    Loss : 39.633644104003906\n",
      "Epoch : 20    Loss : 33.78636169433594\n",
      "Epoch : 21    Loss : 28.80411720275879\n",
      "Epoch : 22    Loss : 24.563812255859375\n",
      "Epoch : 23    Loss : 20.958003997802734\n",
      "Epoch : 24    Loss : 17.89341926574707\n",
      "Epoch : 25    Loss : 15.289509773254395\n",
      "Epoch : 26    Loss : 13.077011108398438\n",
      "Epoch : 27    Loss : 11.196622848510742\n",
      "Epoch : 28    Loss : 9.597736358642578\n",
      "Epoch : 29    Loss : 8.237309455871582\n",
      "Epoch : 30    Loss : 7.078810691833496\n",
      "Epoch : 31    Loss : 6.091297149658203\n",
      "Epoch : 32    Loss : 5.248601913452148\n",
      "Epoch : 33    Loss : 4.528626441955566\n",
      "Epoch : 34    Loss : 3.9127063751220703\n",
      "Epoch : 35    Loss : 3.385105609893799\n",
      "Epoch : 36    Loss : 2.932528495788574\n",
      "Epoch : 37    Loss : 2.5437629222869873\n",
      "Epoch : 38    Loss : 2.2093424797058105\n",
      "Epoch : 39    Loss : 1.9212578535079956\n",
      "Epoch : 40    Loss : 1.6727416515350342\n",
      "Epoch : 41    Loss : 1.458061933517456\n",
      "Epoch : 42    Loss : 1.2723580598831177\n",
      "Epoch : 43    Loss : 1.1115047931671143\n",
      "Epoch : 44    Loss : 0.9719945788383484\n",
      "Epoch : 45    Loss : 0.8508451581001282\n",
      "Epoch : 46    Loss : 0.7455105185508728\n",
      "Epoch : 47    Loss : 0.6538171768188477\n",
      "Epoch : 48    Loss : 0.5739080905914307\n",
      "Epoch : 49    Loss : 0.5041927099227905\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(50):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    losses.append(loss.data.item())\n",
    "    print(f\"Epoch : {epoch}    Loss : {loss.data.item()}\")\n",
    "\n",
    "    # Reset gradients to zero, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "YWL2EbtsWTRZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c9b178ac0>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Loss over time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgRMadtuXkXp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Efm6yU8uRxyk"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
